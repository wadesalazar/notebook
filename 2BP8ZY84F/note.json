{
  "paragraphs": [
    {
      "title": "Load deps",
      "text": "%dep\nz.reset\nz.addRepo(\"hbase-spark\").url(\"https://repository.apache.org/content/repositories/snapshots/\")\nz.load(\"org.apache.hbase:hbase-spark:2.0.0-SNAPSHOT\")",
      "dateUpdated": "Jun 12, 2016 4:56:24 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1465768436914_-1202630133",
      "id": "20160612-165356_324797851",
      "dateCreated": "Jun 12, 2016 4:53:56 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Grab a snapshot of the HBase table",
      "text": "import org.apache.spark._\nimport org.apache.spark.rdd.NewHadoopRDD\nimport org.apache.hadoop.hbase.{HBaseConfiguration, HTableDescriptor}\nimport org.apache.hadoop.hbase.mapreduce.TableInputFormat\nimport java.nio.ByteBuffer\n\n//create a Hbase conf file and set parameters for the scan\nval conf2 \u003d HBaseConfiguration.create()\nconf2.set(TableInputFormat.INPUT_TABLE, \"test\")\nconf2.set(TableInputFormat.SCAN_ROW_START, \"Simulation Examples.Functions.Ramp1-146491000\")\nconf2.set(TableInputFormat.SCAN_ROW_STOP, \"Simulation Examples.Functions.Ramp1-146492000\")\n\n//create a RDD from the table scan\nval hBaseRDD2 \u003d sc.newAPIHadoopRDD(conf2, classOf[org.apache.hadoop.hbase.mapreduce.TableInputFormat],\nclassOf[org.apache.hadoop.hbase.io.ImmutableBytesWritable],\nclassOf[org.apache.hadoop.hbase.client.Result])\n\n//exract and print triple\nval i2 \u003d hBaseRDD2.map(row \u003d\u003e{\n    //retrieve the latest values from each offset cell    \n    for(i \u003c- 0 to 9 if row._2.containsNonEmptyColumn(i.toString.getBytes(),\"id\".getBytes())) yield {\n        //String.valueOf(Array(0).map(_.toByte),\"v\".getBytes()).map(_.toChar)\n        //String.valueOf(row._2.getValue(\"9\".getBytes(),\"id\".getBytes()).map(_.toChar))\n        ((String.valueOf(row._2.getValue(i.toString.getBytes,\"id\".getBytes()).map(_.toChar))),\n        (String.valueOf(row._2.getValue(i.toString.getBytes,\"v\".getBytes()).map(_.toChar))),\n        (String.valueOf(row._2.getValue(i.toString.getBytes,\"t\".getBytes()).map(_.toChar))))\n    }\n\n//convert to RDD[List[List[String]]] \n}).map(n \u003d\u003e {\n    n.toList\n})",
      "dateUpdated": "Jun 12, 2016 4:56:23 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1465768445088_-66451307",
      "id": "20160612-165405_1734641709",
      "dateCreated": "Jun 12, 2016 4:54:05 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Print a few tuples",
      "text": "i2.count\n//print each triple to the screen  \ni2.take(1).foreach(n \u003d\u003e {\n    var itr \u003d n.iterator\n    while(itr.hasNext){\n        val ln \u003d itr.next\n        println(ln._1 + \" \" + ln._2 + \" \" + ln._3)\n    }\n})",
      "dateUpdated": "Jun 12, 2016 4:56:45 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1465768484559_1395792083",
      "id": "20160612-165444_700622531",
      "dateCreated": "Jun 12, 2016 4:54:44 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Cast to DF with the provided schema class and then register as temp table",
      "text": "// Provide a class to describe the schema of the RDD\ncase class Sample( id:String, v:String, t:String)\nval i3 \u003d i2.flatMap(n \u003d\u003e {\n    n\n}).map(n \u003d\u003e \n    Sample(n._1,n._2,n._3)\n)\n\n// Convert RDD to a dataframe then to a table \ni3.toDF().registerTempTable(\"ts_data\")",
      "dateUpdated": "Jun 12, 2016 4:57:28 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1465768493384_1959479870",
      "id": "20160612-165453_2075621431",
      "dateCreated": "Jun 12, 2016 4:54:53 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Query Table",
      "text": "%sql\n\nselect * from ts_data\n\nORDER BY t, id",
      "dateUpdated": "Jun 12, 2016 4:58:28 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true,
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1465768525627_-1409366175",
      "id": "20160612-165525_1825474479",
      "dateCreated": "Jun 12, 2016 4:55:25 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n\nnotes:\n",
      "dateUpdated": "Jun 12, 2016 4:58:31 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1465768653842_1102106079",
      "id": "20160612-165733_1301932104",
      "dateCreated": "Jun 12, 2016 4:57:33 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "HBase Historian Script 1",
  "id": "2BP8ZY84F",
  "angularObjects": {
    "2BQCH17EH:shared_process": [],
    "2BKYFDS7Q:shared_process": [],
    "2BN27KE9W:shared_process": [],
    "2BNR2S1SA:shared_process": [],
    "2BQSD9PWH:shared_process": [],
    "2BNX8S4PE:shared_process": [],
    "2BKYN4BSP:shared_process": [],
    "2BMGY8XB1:shared_process": [],
    "2BMJAS6GB:shared_process": [],
    "2BQ6M2APK:shared_process": [],
    "2BP8PS6E4:shared_process": [],
    "2BM8TNDU6:shared_process": [],
    "2BN3F679N:shared_process": [],
    "2BM19HA25:shared_process": [],
    "2BPTH31JC:shared_process": [],
    "2BPD56EQM:shared_process": [],
    "2BNSFTY5W:shared_process": [],
    "2BQ8KHB3A:shared_process": [],
    "2BQXFYNMJ:shared_process": []
  },
  "config": {},
  "info": {}
}